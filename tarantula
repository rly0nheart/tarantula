#!/usr/bin/env python3

import time
import argparse
from core.__main__ import *
from assets.COLORS import RED,WHITE,GREEN,YELLOW,RESET

if __name__ == "__main__":
	start = time.time()
	end = time.time()-start
	parser = argparse.ArgumentParser(description=f"{WHITE}Tarantula: Web crawler tool developed by {RED}rly0nheart{WHITE} | {RED}https://github.com/rly0nheart{RESET}")
	parser.add_argument("url", help="Target url, starting with https:// or http://")
	parser.add_argument("-c","--count", help="Number of links to crawl, maximum is 30", default=30, type=int, dest="count", metavar="LINKS COUNT")
	parser.add_argument("-v", "--verbose", dest="verbose",action="store_true")
	args = parser.parse_args()
	url = args.url
	max_urls = args.count
	while True:
		try:
			if args.verbose:
				logging.basicConfig(format=f"{WHITE}%(message)s{RESET}",level=logging.DEBUG)
			Tarantula().main(url,max_urls)
			if args.verbose:
			    print(f"{YELLOW}Tarantula{WHITE} stopped in {RED}{end}{WHITE} seconds.{RESET}")
			    break
			    
		except KeyboardInterrupt:
		    if args.verbose:
		    	sys.exit(f"{YELLOW}Process {WHITE}interrupted with {RED}Ctrl{RESET}+{RED}C{RESET}")
		    exit()
		    
		except Exception as e:
		    if args.verbose:
		    	print(f"{WHITE}Error: {RED}{e}{RESET}")
		    	print(f"{WHITE}Retryingâ€¦{RESET}")

		    		
