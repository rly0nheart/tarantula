#!/usr/bin/env python3

import time
import argparse
from core.__main__ import *
from assets.COLORS import RED,WHITE,GREEN,YELLOW,RESET

if __name__ == "__main__":
	start = time.time()
	end = time.time()-start
	parser = argparse.ArgumentParser(description=f"{GREEN}Tarantula{WHITE}: Web crawler and link extractor tool developed by {GREEN}Richard Mwewa{WHITE} | https://github.com/{GREEN}rly0nheart{RESET}")
	parser.add_argument("url", help="Target url, starting with https:// or http://")
	parser.add_argument("-c","--count", help="Number of links to crawl (default is 30)", default=30, type=int, dest="count", metavar="NUMBER")
	parser.add_argument("-v", "--verbose", dest="verbose",action="store_true")
	args = parser.parse_args()
	url = args.url
	max_urls = args.count
	while True:
		try:
			if args.verbose:
				logging.basicConfig(format=f"{WHITE}* %(message)s{RESET}",level=logging.DEBUG)
			Tarantula().main(url,max_urls)
			if args.verbose:
			    print(f"{WHITE}* Stopped in {GREEN}{end}{WHITE} seconds.{RESET}")
			    break
			    
		except KeyboardInterrupt:
		    if args.verbose:
		    	exit(f"{WHITE}* Interrupted with {RED}Ctrl{RESET}+{RED}C{RESET}")
		    break
		    
		except Exception as e:
		    if args.verbose:
		    	print(f"{WHITE}* Error: {RED}{e}{RESET}")
		    	print(f"{WHITE}* Retryingâ€¦{RESET}")

		    		
